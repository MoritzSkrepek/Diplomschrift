\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
    language=Java,
    aboveskip=3mm,
    belowskip=3mm,
    showstringspaces=false,
    columns=flexible,
    basicstyle={\small\ttfamily},
    numbers=left,  % Zeilennummern hinzugefügt
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue},
    commentstyle=\color{dkgreen},
    stringstyle=\color{mauve},
    breaklines=true,
    breakatwhitespace=true,
    tabsize=3
}

\begin{document}

\chapter{Feinkonzept und Realisierung}

\section{Entwicklungsumgebungen}
\subsection{Visual Studio 2022}
Visual Studio 2022 ist eine integrierte Entwicklungsumgebung (IDE) von Microsoft, die speziell für die Entwicklung von
Softwareanwendungen, Webanwendungen und Desktop-Anwendungen konzipiert ist. Es handelt sich um eine umfangreiche
Entwicklungsumgebung, die von Entwicklern weltweit für eine breite Palette von Anwendungsfällen eingesetzt wird.

\subsection{Unity Editor}
Der Unity-Editor ist eine leistungsstarke integrierte Entwicklungsumgebung (IDE) und eine zentrale Arbeitsumgebung
für die Erstellung von 2D-, 3D-, Augmented Reality (AR) und Virtual Reality (VR) Anwendungen und Spielen. Er wird von
Unity Technologies entwickelt und ist die Hauptplattform für die Entwicklung von Unity-basierten Projekten.

\section{Hauptmenu}
Das Hauptmenu dient dazu um das Basic UI/UX System zu implementieren.
Hier kann der Benutzer dann diverse Einstellungen Tätigen als auch
das gewünschte Level auswählen und starten

\subsection{UI/UX}
Mittels verwendung des UX-Tools-Plug-Ins für Mixed Reality wird
mit bereitgestellten Knöpfen, Oberflächen, Comboboxen, etc...
die Benutzeroberfläche erstellt.

\subsection{Laden der Level}
Durch einen Knopfdruck wird dann in Unreal Engine das der ausgewählte
Level geladen.
%Hier dann noch Bilder vom Code einfügen

\section{Ping Level}
In diesem Level wird das IT-Grundprinzip eines Pings zwischen zweier
PCs dargestellt. Das Kabel zwischen den zwei PCs wird von der
HoloLens getracked und mittels Kurvenberechnung wird dann eine
unsichtbare Kurve über dieses Kabel gezeichnet. Wenn dann der Benutzer
auf die Enter Taste auf einem PC drückt wird ein Ping-Paket simuliert
und auf dieser Kurve von einem PC zu dem anderen geschickt.

\subsection{Object Tracking}
Durch verwendung von bereitgestellten Technologien der HoloLens2
werden die zwei PCs und das Kabel getracked.
%Hier dann noch code zum Object Tracking einfügen

\subsection{Kurvenberechnung}
Durch Berechnung der Kurve wird das Kabel als Kurve gespeichert
und dadurch wird es ermöglicht, dass das 3D-Ping-Paket über diese
Kurve von einem PC zum anderen läuft.
%Hier dann noch code zur Kurvenberechnung einfügen

\section{Knappsack Problem Level}
In diesem Level wird das IT-Grundprinzip des Knappsack-Problems dargestellt.
Auf einem Tisch wird mittels Spatial Mapping die Oberfläche des Tisches
getracked und dann ein Spatial Anchor platziert. Auf diesem Anchor wird
anschließend der Inventar-Actor platziert. Außerdem liegen auf dem Tisch
verteilt reale Gegenstände die mit einem QR-Code versehen sind. Nimmt der
Spieler einen Gegenstand in die Hand, wird der QR-Code von der HoloLens2
erfasst. Darauf folgend wird der Inhalt des QR-Codes geladen und in einem
Fenster angezeigt. Der Benutzer kann die Gegenstände frei in das Inventar
verteilen und pro neuen Gegenstand wird ein Inventar-Value berechnet.
Wenn der Benutzer mit seiner Lösung zufrieden ist, kann er anschließend
durch einen Kopfdruck die perfekte Lösung in einem zweiten Inventar anzeigen
lassen.

\subsection{Spatial Anchors}
Spatial Anchors\footnote{Unity \cite{Anchor}} sind virtuelle Ankerpunkte in einer Augmented Reality (AR)- oder Mixed Reality-Umgebung, die dazu dienen,
virtuelle Objekte stabil und präzise in der realen Welt zu verankern. Diese Ankerpunkte ermöglichen es AR- und
MR-Anwendungen, die räumliche Beziehung zwischen virtuellen Objekten und der physischen Umgebung zu speichern und
beizubehalten. Spatial Anchors sind besonders wichtig, wenn es darum geht, AR-Objekte konsistent in der realen Welt
zu positionieren, unabhängig davon, wie sich der Benutzer oder das AR-Gerät bewegt.

\subsection{Managers}
In diesem Level werden mehrere von Unity und dem Mixed Reality Toolkit 3 bereits
bereitgestellten Manager \footnote{Medium \cite{Managers}} verwendet. Unter einer Manager
versteht man eine Komponente die einer Unity-Scene hinzugefügt wird die dazu dient,
bestimmte Aspekte oder Funktionen der Anwendung zu verwalten und zu stuern. Diese Manager
spielen eine wichtige Rolle in der Organisation und Kontroller verschiedener Teile der Unity-Anwendung.
In dem "Knappsack Problem Level" werden folgende Manager verwendet:
\begin{itemize}
    \item ARPlaneManager\footnote{Unity \cite{PlaneManager}}:\\
    Dieser Manager wird verwendet um in der Umgebung des Benutzers alle Horizontalen Flächen zu erkennen und zu tracken.
    Außerdem erleichtert er das platzieren von Objekten in der echten Welt.
    Diese Flächen werden anschließend mit einer Textur markiert. Wenn der User für die vorgeschriebene
    Zeit auf eine dieser Flächen schaut wird in der Mitte dieser Fläche das Inventar als 3D Objekt dargestellt. An dieses
    3D Objekt wird anschließend auch ein Spatial Anchor angehängt und in dem ARAnchorManager verwaltet.

    \item ARAnchorManager\footnote{Unity \cite{AnchorManager}}: \\
    Dieser Manager wird verwendet um AR-Anker in der AR-Welt und der echten Welt zu erstellen, zu verankern und zu verwalten.
    In dem "Knappsack Problem Level" wird dieser Manager gebraucht, weil wir das Inventar sowohl in der AR, als auch in
    der echten Welt verankern müssen. An der Stelle wo das Inventar verankert wird, wird anschließend ein ARAnchor \footnote{Unity \cite{Anchor}}
    erstellt, der von der HoloLens2 getracked wird.

    \item ARRaycastManager\footnote{Unity \cite{RaycastManager}}; \\
    Dieser Manager wird verwendet um aus einem Origin Punkt also in diesem Fall die Kamera der HoloLens2, raycasting durchzuführen.
    Diese Raycasts treffen dann auf bereits markierte und getrackte Planes. Wenn dies der Fall ist, ist bekannt, dass der
    Benutzer auf dieses Plane sieht. Dies ermöglicht dann eine akkurate Platzierung eines 3D Objekts in der realen Welt. \\

\end{itemize}
In dem folgendem Code Abscnhitt wird dargestellt wie die drei Manager alle zusammenspielen, um in der realen Welt
ein 3D Objekt zu verankern:

\begin{lstlisting}[language=Java, style=csharpstyle, caption=3D Objekt in der echten Welt platzieren]
using System.Collections.Generic;
using Unity.VisualScripting;
using UnityEngine;
using UnityEngine.XR.ARFoundation;
using UnityEngine.XR.ARSubsystems;

public class PlaceObjectOnLookedAtDesk : MonoBehaviour
{
    public ARRaycastManager raycastManager;
    public ARPlaneManager planeManager;
    public ARAnchorManager anchorManager;
    public GameObject objectToPlace;
    public float requiredLookTime = 3.0f;

    private ARPlane selectedDeskPlane;
    private float lookStartTime = -1f;
    private bool objectPlaced = false;
    private float heightOffset = 0.05f;

    //Gets called every frame
    void Update()
    {
        if (!objectPlaced)
        {
            List<ARRaycastHit> hits = new List<ARRaycastHit>();
            //if true the player is looking at a plane
            if (raycastManager.Raycast(new Vector2(Screen.width / 2, Screen.height / 2), hits, TrackableType.Planes))
            {
                ARPlane plane = planeManager.GetPlane(hits[0].trackableId);
                if (plane != null)
                {
                    if (selectedDeskPlane == null)
                    {
                        selectedDeskPlane = plane;
                        lookStartTime = Time.time; // Start the timer when a new plane is selected.
                        Debug.Log("Plane selected. Timer started.");
                    }
                    if (selectedDeskPlane == plane)
                    {
                        //start timer
                        float timeLookedAtPlane = Time.time - lookStartTime;
                        if (timeLookedAtPlane >= requiredLookTime)
                        {
                            PlaceObjectOnDesk(selectedDeskPlane);
                            objectPlaced = true;
                        }
                    }
                    else
                    {
                        selectedDeskPlane = null;
                    }
                }
                else
                {
                    selectedDeskPlane = null;
                }
            }
            else
            {
                selectedDeskPlane = null;
            }
        }
    }

    void PlaceObjectOnDesk(ARPlane deskPlane)
    {
        // Disable the plane manager to stop further plane detection.
        planeManager.enabled = false;
        // Disable this script so it won't run again.
        gameObject.SetActive(false);
        // Calculate the object's position above the center of the plane.
        Vector3 objectPosition = deskPlane.center + Vector3.up * heightOffset;
        // Instantiate the object and place it at the calculated position.
        Instantiate(objectToPlace, objectPosition, Quaternion.identity);


        /*
        //This code handles the calculation for the placement position and also attaches an ARAnchor to the placed Object
        // Disable the plane manager to stop further plane detection.
        planeManager.enabled = false;

        // Disable this script so it won't run again.
        gameObject.SetActive(false);

        // Calculate the object's position above the center of the plane.
        Vector3 objectPosition = deskPlane.center + Vector3.up * heightOffset;

        //Create Anchor
        ARAnchor newAnchor = anchorManager.AddComponent<ARAnchor>();
        GameObject anchorVisual = Instantiate(objectToPlace, objectPosition, Quaternion.identity);
        anchorVisual.transform.parent = newAnchor.transform;
        */
    }
}

\end{lstlisting}

\subsection{QR-Code Tagging}
Generierte QR-Codes werden auf die realen Objekte geklebt. In diesen QR-Codes werden
wichtige Informationen zu den Objekten gespeichert. Darunten sind folgende Elemente:
Gewicht, Wert und eine kurze Beschreibung zu diesem Objekt.

\subsection{QR-Code Tracking}
Durch Verwendung der integrierten Kamera rendert die HoloLens2 existente QR-Codes an
der Originalen Positionen in 3D-Objekte. Mittels tracking kann dann auch der Inhalt
der getracked QR-Codes geladen werden.
%Genauer Beschreibung + wenn vorhanden Code und Blueprints von QR-Code-Tracking hinzufügen

\subsection{Knappsack-Algorithmus}
%Hier kommt dann ein Bild von dem Level Blueprint + Custom Code vom Knappsack Algorithmus mit erklärung
Durch Interaktion zwischen echten und 3D-Obejekt können

\subsection{Unit-Tests}
Durch Hilfe von Unit-Tests wird versichert, dass der implementierte Knappsack-Algorithmus
richtig und performant funktioniert.
%Genauere Erklärung + Custom Code der UnitTests

\section{Performance}
Performance-Messung

\end{document}